{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download GloVe from below:\n",
    "#### http://nlp.stanford.edu/data/glove.6B.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "import networkx as nx\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/DataScienceCollection/GloVe/Data/tennis_articles_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Maria Sharapova has basically no friends as te...\n",
       "1    BASEL, Switzerland (AP), Roger Federer advance...\n",
       "2    Roger Federer has revealed that organisers of ...\n",
       "3    Kei Nishikori will try to end his long losing ...\n",
       "4    Federer, 37, first broke through on tour over ...\n",
       "5    Nadal has not played tennis since he was force...\n",
       "6    Tennis giveth, and tennis taketh away. The end...\n",
       "7    Federer won the Swiss Indoors last week by bea...\n",
       "Name: article_text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['article_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now, let's work on Maria Sharapova's Text Summary. i.e, index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maria Sharapova has basically no friends as tennis players on the WTA Tour.', \"The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much.\", 'I think everyone knows this is my job here.', \"When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.\", \"So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.\", \"I'm a pretty competitive girl.\", \"I say my hellos, but I'm not sending any players flowers as well.\", \"Uhm, I'm not really friendly or close to many players.\", \"I have not a lot of friends away from the courts.'\", 'When she said she is not really close to a lot of players, is that something strategic that she is doing?', \"Is it different on the men's tour than the women's tour? '\", 'No, not at all.', \"I think just because you're in the same sport doesn't mean that you have to be friends with everyone just because you're categorized\", \", you're a tennis player,\", \"so you're going to get along with tennis players.\", 'I think every person has different interests.', \"I have friends that have completely different jobs and interests, and I've met them in very different parts of my life.\", \"I think everyone just thinks because we're tennis players we should be the greatest of friends.\", 'But ultimately tennis is just a very small part of what we do.', \"There are so many other things that we're interested in, that we do.'\"]\n"
     ]
    }
   ],
   "source": [
    "row = data['article_text'][0]\n",
    "doc = nlp(row)\n",
    "sentences=[sent.string.strip() for sent in doc.sents]\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we have the list of sentences, let's make this above list of sentences as list of 'cleaner sentences'. When said 'cleaner' it means removal of STOP WORDs, removal of Punctuations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "punctuations = string.punctuation\n",
    "\n",
    "data = []\n",
    "dataAfterStopwordsFilter =[]\n",
    "dataAfterPunctuationsFilter =[]\n",
    "dataAfterLowerCase =[]\n",
    "refinedList = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    docx = nlp(sentence)\n",
    "    for token in docx:\n",
    "        data.append(token.text)\n",
    "    for token in data:    \n",
    "        if token != stopwords:\n",
    "            dataAfterStopwordsFilter.append(token)\n",
    "    for token in dataAfterStopwordsFilter:\n",
    "        if token not in punctuations:\n",
    "            dataAfterPunctuationsFilter.append(token)\n",
    "    for token in dataAfterPunctuationsFilter:\n",
    "        dataAfterLowerCase.append(token.lower().strip())    \n",
    "    #Appending Clean Sentences in a list.\n",
    "    refinedList.append(dataAfterLowerCase)          \n",
    "    data = []\n",
    "    dataAfterStopwordsFilter =[]\n",
    "    dataAfterPunctuationsFilter =[]\n",
    "    dataAfterLowerCase =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maria',\n",
       " 'sharapova',\n",
       " 'have',\n",
       " 'basically',\n",
       " 'no',\n",
       " 'friend',\n",
       " 'as',\n",
       " 'tennis',\n",
       " 'player',\n",
       " 'on',\n",
       " 'the',\n",
       " 'wta',\n",
       " 'tour',\n",
       " 'the',\n",
       " 'russian',\n",
       " 'player',\n",
       " 'have',\n",
       " 'no',\n",
       " 'problem',\n",
       " 'in',\n",
       " 'openly',\n",
       " 'speak',\n",
       " 'about',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'interview',\n",
       " 'say',\n",
       " 'do',\n",
       " 'not',\n",
       " 'really',\n",
       " 'hide',\n",
       " 'any',\n",
       " 'feeling',\n",
       " 'too',\n",
       " 'much',\n",
       " 'think',\n",
       " 'everyone',\n",
       " 'know',\n",
       " 'this',\n",
       " 'be',\n",
       " 'job',\n",
       " 'here',\n",
       " 'when',\n",
       " 'be',\n",
       " 'on',\n",
       " 'the',\n",
       " 'court',\n",
       " 'or',\n",
       " 'when',\n",
       " 'be',\n",
       " 'on',\n",
       " 'the',\n",
       " 'court',\n",
       " 'playing',\n",
       " 'be',\n",
       " 'a',\n",
       " 'competitor',\n",
       " 'and',\n",
       " 'want',\n",
       " 'to',\n",
       " 'beat',\n",
       " 'every',\n",
       " 'single',\n",
       " 'person',\n",
       " 'whether',\n",
       " 'be',\n",
       " 'in',\n",
       " 'the',\n",
       " 'locker',\n",
       " 'room',\n",
       " 'or',\n",
       " 'across',\n",
       " 'the',\n",
       " 'net',\n",
       " 'so',\n",
       " 'be',\n",
       " 'not',\n",
       " 'the',\n",
       " 'one',\n",
       " 'to',\n",
       " 'strike',\n",
       " 'up',\n",
       " 'a',\n",
       " 'conversation',\n",
       " 'about',\n",
       " 'the',\n",
       " 'weather',\n",
       " 'and',\n",
       " 'know',\n",
       " 'that',\n",
       " 'in',\n",
       " 'the',\n",
       " 'next',\n",
       " 'few',\n",
       " 'minute',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'and',\n",
       " 'try',\n",
       " 'to',\n",
       " 'win',\n",
       " 'a',\n",
       " 'tennis',\n",
       " 'match',\n",
       " 'be',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'competitive',\n",
       " 'girl',\n",
       " 'say',\n",
       " 'hello',\n",
       " 'but',\n",
       " 'be',\n",
       " 'not',\n",
       " 'send',\n",
       " 'any',\n",
       " 'player',\n",
       " 'flower',\n",
       " 'as',\n",
       " 'well',\n",
       " 'uhm',\n",
       " 'be',\n",
       " 'not',\n",
       " 'really',\n",
       " 'friendly',\n",
       " 'or',\n",
       " 'close',\n",
       " 'to',\n",
       " 'many',\n",
       " 'player',\n",
       " 'have',\n",
       " 'not',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'friend',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'court',\n",
       " 'when',\n",
       " 'say',\n",
       " 'be',\n",
       " 'not',\n",
       " 'really',\n",
       " 'close',\n",
       " 'to',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'player',\n",
       " 'be',\n",
       " 'that',\n",
       " 'something',\n",
       " 'strategic',\n",
       " 'that',\n",
       " 'be',\n",
       " 'do',\n",
       " 'be',\n",
       " 'different',\n",
       " 'on',\n",
       " 'the',\n",
       " 'man',\n",
       " \"'s\",\n",
       " 'tour',\n",
       " 'than',\n",
       " 'the',\n",
       " 'woman',\n",
       " \"'s\",\n",
       " 'tour',\n",
       " 'no',\n",
       " 'not',\n",
       " 'at',\n",
       " 'all',\n",
       " 'think',\n",
       " 'just',\n",
       " 'because',\n",
       " 'be',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'sport',\n",
       " 'do',\n",
       " 'not',\n",
       " 'mean',\n",
       " 'that',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'friend',\n",
       " 'with',\n",
       " 'everyone',\n",
       " 'just',\n",
       " 'because',\n",
       " 'be',\n",
       " 'categorize',\n",
       " 'be',\n",
       " 'a',\n",
       " 'tennis',\n",
       " 'player',\n",
       " 'so',\n",
       " 'be',\n",
       " 'go',\n",
       " 'to',\n",
       " 'get',\n",
       " 'along',\n",
       " 'with',\n",
       " 'tennis',\n",
       " 'player',\n",
       " 'think',\n",
       " 'every',\n",
       " 'person',\n",
       " 'have',\n",
       " 'different',\n",
       " 'interest',\n",
       " 'have',\n",
       " 'friend',\n",
       " 'that',\n",
       " 'have',\n",
       " 'completely',\n",
       " 'different',\n",
       " 'job',\n",
       " 'and',\n",
       " 'interest',\n",
       " 'and',\n",
       " 'have',\n",
       " 'meet',\n",
       " 'in',\n",
       " 'very',\n",
       " 'different',\n",
       " 'part',\n",
       " 'of',\n",
       " 'life',\n",
       " 'think',\n",
       " 'everyone',\n",
       " 'just',\n",
       " 'think',\n",
       " 'because',\n",
       " 'be',\n",
       " 'tennis',\n",
       " 'player',\n",
       " 'should',\n",
       " 'be',\n",
       " 'the',\n",
       " 'great',\n",
       " 'of',\n",
       " 'friend',\n",
       " 'but',\n",
       " 'ultimately',\n",
       " 'tennis',\n",
       " 'be',\n",
       " 'just',\n",
       " 'a',\n",
       " 'very',\n",
       " 'small',\n",
       " 'part',\n",
       " 'of',\n",
       " 'what',\n",
       " 'do',\n",
       " 'there',\n",
       " 'be',\n",
       " 'so',\n",
       " 'many',\n",
       " 'other',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'be',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'that',\n",
       " 'do']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refinedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfCleanSentences = []\n",
    "\n",
    "for sentence in refinedList:\n",
    "    listOfCleanSentences.append(' '.join(sentence))\n",
    "    \n",
    "listOfCleanSentences  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducing GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word vectors \n",
    "word_embeddings = {} \n",
    "f = open('D:/DataScienceCollection/GloVe/glove.6B.100d.txt', encoding='utf-8') \n",
    "for line in f: \n",
    "    values = line.split() \n",
    "    word = values[0] \n",
    "    coefs = np.asarray(values[1:], dtype='float32')   \n",
    "    word_embeddings[word] = coefs \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in cleanSentences:\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to find similarities among the sentences. We will use cosine similarity to find similarity between a pair of sentences. Let's create an empty similarity matrix for this task and populate it with cosine similarities of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I say my hellos, but I'm not sending any players flowers as well.\n",
      "Is it different on the men's tour than the women's tour? '\n",
      ", you're a tennis player,\n",
      "So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.\n",
      "I think everyone just thinks because we're tennis players we should be the greatest of friends.\n",
      "I think everyone knows this is my job here.\n",
      "I have friends that have completely different jobs and interests, and I've met them in very different parts of my life.\n",
      "When she said she is not really close to a lot of players, is that something strategic that she is doing?\n",
      "There are so many other things that we're interested in, that we do.'\n",
      "I think every person has different interests.\n"
     ]
    }
   ],
   "source": [
    "# Specify number of sentences to form the summary\n",
    "sn = 10\n",
    "\n",
    "# Generate summary\n",
    "for i in range(sn):\n",
    "    print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
